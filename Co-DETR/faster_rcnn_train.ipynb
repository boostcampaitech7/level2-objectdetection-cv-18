{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 모듈 import\n",
    "\n",
    "from mmcv import Config\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "from mmdet.datasets import (build_dataloader, build_dataset,\n",
    "                            replace_ImageToTensor)\n",
    "from mmdet.utils import get_device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "\n",
    "# config file 들고오기\n",
    "cfg = Config.fromfile('./projects/configs/co_dino_vit/co_dino_5scale_vit_large_coco.py') # faster_rcnn/faster_rcnn_r50_fpn_1x_coco.py\n",
    "root='../../../../dataset/' \n",
    "\n",
    "# dataset config 수정\n",
    "cfg.data.train.classes = classes\n",
    "cfg.data.train.img_prefix = root\n",
    "cfg.data.train.ann_file = root + 'train.json' # train json 정보\n",
    "# cfg.data.train.pipeline[2]['img_scale'] = (512,512) # Resize\n",
    "\n",
    "cfg.data.test.classes = classes\n",
    "cfg.data.test.img_prefix = root\n",
    "cfg.data.test.ann_file = root + 'test.json' # test json 정보\n",
    "# cfg.data.test.pipeline[1]['img_scale'] = (512,512) # Resize\n",
    "\n",
    "cfg.data.samples_per_gpu = 1\n",
    "cfg.data.workers_per_gpu = 1\n",
    "\n",
    "cfg.seed = 2022\n",
    "cfg.gpu_ids = [0]\n",
    "cfg.work_dir = './work_dirs/co_dino_5scale_vit_large_coco_transfer'\n",
    "cfg.model.query_head.num_classes = 10\n",
    "cfg.model.roi_head[0].bbox_head.num_classes = 10\n",
    "cfg.model.bbox_head[0].num_classes = 10\n",
    "\n",
    "cfg.optimizer_config.grad_clip = dict(max_norm=35, norm_type=2)\n",
    "cfg.checkpoint_config = dict(max_keep_ckpts=3, interval=1)\n",
    "cfg.device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "# build_dataset\n",
    "datasets = [build_dataset(cfg.data.train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "CocoDataset Train dataset with number of images 4883, and instance counts: \n",
       "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
       "| category          | count | category      | count | category        | count | category    | count | category     | count |\n",
       "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+\n",
       "| 0 [General trash] | 3965  | 1 [Paper]     | 6352  | 2 [Paper pack]  | 897   | 3 [Metal]   | 936   | 4 [Glass]    | 982   |\n",
       "| 5 [Plastic]       | 2943  | 6 [Styrofoam] | 1263  | 7 [Plastic bag] | 5178  | 8 [Battery] | 159   | 9 [Clothing] | 468   |\n",
       "+-------------------+-------+---------------+-------+-----------------+-------+-------------+-------+--------------+-------+"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset 확인\n",
    "datasets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== shape of rope freq torch.Size([576, 64]) ========\n",
      "======== shape of rope freq torch.Size([9216, 64]) ========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 20:01:16,186 - mmcv - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n",
      "2024-10-07 20:01:16,196 - mmcv - INFO - \n",
      "rpn_conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-10-07 20:01:16,196 - mmcv - INFO - \n",
      "rpn_conv.bias - torch.Size([256]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-10-07 20:01:16,197 - mmcv - INFO - \n",
      "rpn_cls.weight - torch.Size([9, 256, 1, 1]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-10-07 20:01:16,198 - mmcv - INFO - \n",
      "rpn_cls.bias - torch.Size([9]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-10-07 20:01:16,198 - mmcv - INFO - \n",
      "rpn_reg.weight - torch.Size([36, 256, 1, 1]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-10-07 20:01:16,198 - mmcv - INFO - \n",
      "rpn_reg.bias - torch.Size([36]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-10-07 20:01:16,385 - mmcv - INFO - initialize ConvFCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n",
      "2024-10-07 20:01:16,512 - mmcv - INFO - \n",
      "bbox_head.fc_cls.weight - torch.Size([11, 1024]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-10-07 20:01:16,513 - mmcv - INFO - \n",
      "bbox_head.fc_cls.bias - torch.Size([11]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-10-07 20:01:16,513 - mmcv - INFO - \n",
      "bbox_head.fc_reg.weight - torch.Size([4, 1024]): \n",
      "NormalInit: mean=0, std=0.001, bias=0 \n",
      " \n",
      "2024-10-07 20:01:16,514 - mmcv - INFO - \n",
      "bbox_head.fc_reg.bias - torch.Size([4]): \n",
      "NormalInit: mean=0, std=0.001, bias=0 \n",
      " \n",
      "2024-10-07 20:01:16,514 - mmcv - INFO - \n",
      "bbox_head.shared_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CoStandardRoIHead  \n",
      " \n",
      "2024-10-07 20:01:16,515 - mmcv - INFO - \n",
      "bbox_head.shared_convs.0.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoStandardRoIHead  \n",
      " \n",
      "2024-10-07 20:01:16,516 - mmcv - INFO - \n",
      "bbox_head.shared_convs.0.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoStandardRoIHead  \n",
      " \n",
      "2024-10-07 20:01:16,516 - mmcv - INFO - \n",
      "bbox_head.shared_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CoStandardRoIHead  \n",
      " \n",
      "2024-10-07 20:01:16,517 - mmcv - INFO - \n",
      "bbox_head.shared_convs.1.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoStandardRoIHead  \n",
      " \n",
      "2024-10-07 20:01:16,517 - mmcv - INFO - \n",
      "bbox_head.shared_convs.1.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoStandardRoIHead  \n",
      " \n",
      "2024-10-07 20:01:16,517 - mmcv - INFO - \n",
      "bbox_head.shared_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CoStandardRoIHead  \n",
      " \n",
      "2024-10-07 20:01:16,518 - mmcv - INFO - \n",
      "bbox_head.shared_convs.2.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoStandardRoIHead  \n",
      " \n",
      "2024-10-07 20:01:16,518 - mmcv - INFO - \n",
      "bbox_head.shared_convs.2.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoStandardRoIHead  \n",
      " \n",
      "2024-10-07 20:01:16,519 - mmcv - INFO - \n",
      "bbox_head.shared_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CoStandardRoIHead  \n",
      " \n",
      "2024-10-07 20:01:16,519 - mmcv - INFO - \n",
      "bbox_head.shared_convs.3.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoStandardRoIHead  \n",
      " \n",
      "2024-10-07 20:01:16,520 - mmcv - INFO - \n",
      "bbox_head.shared_convs.3.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoStandardRoIHead  \n",
      " \n",
      "2024-10-07 20:01:16,520 - mmcv - INFO - \n",
      "bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-10-07 20:01:16,521 - mmcv - INFO - \n",
      "bbox_head.shared_fcs.0.bias - torch.Size([1024]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "/data/ephemeral/home/taehan/test/level2-objectdetection-cv-18/Co-DETR/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n",
      "2024-10-07 20:01:16,550 - mmcv - INFO - initialize CoATSSHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'atss_cls', 'std': 0.01, 'bias_prob': 0.01}}\n",
      "2024-10-07 20:01:16,563 - mmcv - INFO - \n",
      "cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-10-07 20:01:16,563 - mmcv - INFO - \n",
      "cls_convs.0.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "2024-10-07 20:01:16,564 - mmcv - INFO - \n",
      "cls_convs.0.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "2024-10-07 20:01:16,565 - mmcv - INFO - \n",
      "reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-10-07 20:01:16,565 - mmcv - INFO - \n",
      "reg_convs.0.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "2024-10-07 20:01:16,566 - mmcv - INFO - \n",
      "reg_convs.0.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "2024-10-07 20:01:16,566 - mmcv - INFO - \n",
      "atss_cls.weight - torch.Size([10, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
      " \n",
      "2024-10-07 20:01:16,567 - mmcv - INFO - \n",
      "atss_cls.bias - torch.Size([10]): \n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
      " \n",
      "2024-10-07 20:01:16,567 - mmcv - INFO - \n",
      "atss_reg.weight - torch.Size([4, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-10-07 20:01:16,568 - mmcv - INFO - \n",
      "atss_reg.bias - torch.Size([4]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-10-07 20:01:16,569 - mmcv - INFO - \n",
      "atss_centerness.weight - torch.Size([1, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-10-07 20:01:16,569 - mmcv - INFO - \n",
      "atss_centerness.bias - torch.Size([1]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "2024-10-07 20:01:16,570 - mmcv - INFO - \n",
      "scales.0.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "2024-10-07 20:01:16,571 - mmcv - INFO - \n",
      "scales.1.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "2024-10-07 20:01:16,571 - mmcv - INFO - \n",
      "scales.2.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "2024-10-07 20:01:16,572 - mmcv - INFO - \n",
      "scales.3.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "2024-10-07 20:01:16,573 - mmcv - INFO - \n",
      "scales.4.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "2024-10-07 20:01:16,573 - mmcv - INFO - \n",
      "scales.5.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "2024-10-07 20:01:16,669 - mmdet - WARNING - No pre-trained weights for ViT, training start from scratch\n",
      "2024-10-07 20:01:19,081 - mmcv - INFO - initialize SFP with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "/opt/conda/lib/python3.10/site-packages/mmcv/runner/base_module.py:127: UserWarning: init_weights of RPNHead has been called more than once.\n",
      "  warnings.warn(f'init_weights of {self.__class__.__name__} has '\n",
      "2024-10-07 20:01:19,425 - mmcv - INFO - \n",
      "backbone.pos_embed - torch.Size([1, 1025, 1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,426 - mmcv - INFO - \n",
      "backbone.patch_embed.proj.weight - torch.Size([1024, 3, 16, 16]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,426 - mmcv - INFO - \n",
      "backbone.patch_embed.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,427 - mmcv - INFO - \n",
      "backbone.blocks.0.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,428 - mmcv - INFO - \n",
      "backbone.blocks.0.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,429 - mmcv - INFO - \n",
      "backbone.blocks.0.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,429 - mmcv - INFO - \n",
      "backbone.blocks.0.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,430 - mmcv - INFO - \n",
      "backbone.blocks.0.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,431 - mmcv - INFO - \n",
      "backbone.blocks.0.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,431 - mmcv - INFO - \n",
      "backbone.blocks.0.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,432 - mmcv - INFO - \n",
      "backbone.blocks.0.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,432 - mmcv - INFO - \n",
      "backbone.blocks.0.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,433 - mmcv - INFO - \n",
      "backbone.blocks.0.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,434 - mmcv - INFO - \n",
      "backbone.blocks.0.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,435 - mmcv - INFO - \n",
      "backbone.blocks.0.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,436 - mmcv - INFO - \n",
      "backbone.blocks.0.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,436 - mmcv - INFO - \n",
      "backbone.blocks.0.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,437 - mmcv - INFO - \n",
      "backbone.blocks.0.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,437 - mmcv - INFO - \n",
      "backbone.blocks.0.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,438 - mmcv - INFO - \n",
      "backbone.blocks.0.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,438 - mmcv - INFO - \n",
      "backbone.blocks.0.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,439 - mmcv - INFO - \n",
      "backbone.blocks.0.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,439 - mmcv - INFO - \n",
      "backbone.blocks.1.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,440 - mmcv - INFO - \n",
      "backbone.blocks.1.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,440 - mmcv - INFO - \n",
      "backbone.blocks.1.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,442 - mmcv - INFO - \n",
      "backbone.blocks.1.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,443 - mmcv - INFO - \n",
      "backbone.blocks.1.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,443 - mmcv - INFO - \n",
      "backbone.blocks.1.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,444 - mmcv - INFO - \n",
      "backbone.blocks.1.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,445 - mmcv - INFO - \n",
      "backbone.blocks.1.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,446 - mmcv - INFO - \n",
      "backbone.blocks.1.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,446 - mmcv - INFO - \n",
      "backbone.blocks.1.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,447 - mmcv - INFO - \n",
      "backbone.blocks.1.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,447 - mmcv - INFO - \n",
      "backbone.blocks.1.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,448 - mmcv - INFO - \n",
      "backbone.blocks.1.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,448 - mmcv - INFO - \n",
      "backbone.blocks.1.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,449 - mmcv - INFO - \n",
      "backbone.blocks.1.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,449 - mmcv - INFO - \n",
      "backbone.blocks.1.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,450 - mmcv - INFO - \n",
      "backbone.blocks.1.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,450 - mmcv - INFO - \n",
      "backbone.blocks.1.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,451 - mmcv - INFO - \n",
      "backbone.blocks.1.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,453 - mmcv - INFO - \n",
      "backbone.blocks.2.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,453 - mmcv - INFO - \n",
      "backbone.blocks.2.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,454 - mmcv - INFO - \n",
      "backbone.blocks.2.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,454 - mmcv - INFO - \n",
      "backbone.blocks.2.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,455 - mmcv - INFO - \n",
      "backbone.blocks.2.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,455 - mmcv - INFO - \n",
      "backbone.blocks.2.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,456 - mmcv - INFO - \n",
      "backbone.blocks.2.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,456 - mmcv - INFO - \n",
      "backbone.blocks.2.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,457 - mmcv - INFO - \n",
      "backbone.blocks.2.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,457 - mmcv - INFO - \n",
      "backbone.blocks.2.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,458 - mmcv - INFO - \n",
      "backbone.blocks.2.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,458 - mmcv - INFO - \n",
      "backbone.blocks.2.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,458 - mmcv - INFO - \n",
      "backbone.blocks.2.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,459 - mmcv - INFO - \n",
      "backbone.blocks.2.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,461 - mmcv - INFO - \n",
      "backbone.blocks.2.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,462 - mmcv - INFO - \n",
      "backbone.blocks.2.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,463 - mmcv - INFO - \n",
      "backbone.blocks.2.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,463 - mmcv - INFO - \n",
      "backbone.blocks.2.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,464 - mmcv - INFO - \n",
      "backbone.blocks.2.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,464 - mmcv - INFO - \n",
      "backbone.blocks.3.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,465 - mmcv - INFO - \n",
      "backbone.blocks.3.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,465 - mmcv - INFO - \n",
      "backbone.blocks.3.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,466 - mmcv - INFO - \n",
      "backbone.blocks.3.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,466 - mmcv - INFO - \n",
      "backbone.blocks.3.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,467 - mmcv - INFO - \n",
      "backbone.blocks.3.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,467 - mmcv - INFO - \n",
      "backbone.blocks.3.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,470 - mmcv - INFO - \n",
      "backbone.blocks.3.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,470 - mmcv - INFO - \n",
      "backbone.blocks.3.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,471 - mmcv - INFO - \n",
      "backbone.blocks.3.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,471 - mmcv - INFO - \n",
      "backbone.blocks.3.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,471 - mmcv - INFO - \n",
      "backbone.blocks.3.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,472 - mmcv - INFO - \n",
      "backbone.blocks.3.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,473 - mmcv - INFO - \n",
      "backbone.blocks.3.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,473 - mmcv - INFO - \n",
      "backbone.blocks.3.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,474 - mmcv - INFO - \n",
      "backbone.blocks.3.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,474 - mmcv - INFO - \n",
      "backbone.blocks.3.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,475 - mmcv - INFO - \n",
      "backbone.blocks.3.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,475 - mmcv - INFO - \n",
      "backbone.blocks.3.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,476 - mmcv - INFO - \n",
      "backbone.blocks.4.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,478 - mmcv - INFO - \n",
      "backbone.blocks.4.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,478 - mmcv - INFO - \n",
      "backbone.blocks.4.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,479 - mmcv - INFO - \n",
      "backbone.blocks.4.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,479 - mmcv - INFO - \n",
      "backbone.blocks.4.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,480 - mmcv - INFO - \n",
      "backbone.blocks.4.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,480 - mmcv - INFO - \n",
      "backbone.blocks.4.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,481 - mmcv - INFO - \n",
      "backbone.blocks.4.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,481 - mmcv - INFO - \n",
      "backbone.blocks.4.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,482 - mmcv - INFO - \n",
      "backbone.blocks.4.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,482 - mmcv - INFO - \n",
      "backbone.blocks.4.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,483 - mmcv - INFO - \n",
      "backbone.blocks.4.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,483 - mmcv - INFO - \n",
      "backbone.blocks.4.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,484 - mmcv - INFO - \n",
      "backbone.blocks.4.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,484 - mmcv - INFO - \n",
      "backbone.blocks.4.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,485 - mmcv - INFO - \n",
      "backbone.blocks.4.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,485 - mmcv - INFO - \n",
      "backbone.blocks.4.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,486 - mmcv - INFO - \n",
      "backbone.blocks.4.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,486 - mmcv - INFO - \n",
      "backbone.blocks.4.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,487 - mmcv - INFO - \n",
      "backbone.blocks.5.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,487 - mmcv - INFO - \n",
      "backbone.blocks.5.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,488 - mmcv - INFO - \n",
      "backbone.blocks.5.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,488 - mmcv - INFO - \n",
      "backbone.blocks.5.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,491 - mmcv - INFO - \n",
      "backbone.blocks.5.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,492 - mmcv - INFO - \n",
      "backbone.blocks.5.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,492 - mmcv - INFO - \n",
      "backbone.blocks.5.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,493 - mmcv - INFO - \n",
      "backbone.blocks.5.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,493 - mmcv - INFO - \n",
      "backbone.blocks.5.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,494 - mmcv - INFO - \n",
      "backbone.blocks.5.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,494 - mmcv - INFO - \n",
      "backbone.blocks.5.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,495 - mmcv - INFO - \n",
      "backbone.blocks.5.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,495 - mmcv - INFO - \n",
      "backbone.blocks.5.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,496 - mmcv - INFO - \n",
      "backbone.blocks.5.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,497 - mmcv - INFO - \n",
      "backbone.blocks.5.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,497 - mmcv - INFO - \n",
      "backbone.blocks.5.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,497 - mmcv - INFO - \n",
      "backbone.blocks.5.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,498 - mmcv - INFO - \n",
      "backbone.blocks.5.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,498 - mmcv - INFO - \n",
      "backbone.blocks.5.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,499 - mmcv - INFO - \n",
      "backbone.blocks.6.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,499 - mmcv - INFO - \n",
      "backbone.blocks.6.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,500 - mmcv - INFO - \n",
      "backbone.blocks.6.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,500 - mmcv - INFO - \n",
      "backbone.blocks.6.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,503 - mmcv - INFO - \n",
      "backbone.blocks.6.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,503 - mmcv - INFO - \n",
      "backbone.blocks.6.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,504 - mmcv - INFO - \n",
      "backbone.blocks.6.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,504 - mmcv - INFO - \n",
      "backbone.blocks.6.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,505 - mmcv - INFO - \n",
      "backbone.blocks.6.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,505 - mmcv - INFO - \n",
      "backbone.blocks.6.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,506 - mmcv - INFO - \n",
      "backbone.blocks.6.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,506 - mmcv - INFO - \n",
      "backbone.blocks.6.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,507 - mmcv - INFO - \n",
      "backbone.blocks.6.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,507 - mmcv - INFO - \n",
      "backbone.blocks.6.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,509 - mmcv - INFO - \n",
      "backbone.blocks.6.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,510 - mmcv - INFO - \n",
      "backbone.blocks.6.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,510 - mmcv - INFO - \n",
      "backbone.blocks.6.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,511 - mmcv - INFO - \n",
      "backbone.blocks.6.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,511 - mmcv - INFO - \n",
      "backbone.blocks.6.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,512 - mmcv - INFO - \n",
      "backbone.blocks.7.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,512 - mmcv - INFO - \n",
      "backbone.blocks.7.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,513 - mmcv - INFO - \n",
      "backbone.blocks.7.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,513 - mmcv - INFO - \n",
      "backbone.blocks.7.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,514 - mmcv - INFO - \n",
      "backbone.blocks.7.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,514 - mmcv - INFO - \n",
      "backbone.blocks.7.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,515 - mmcv - INFO - \n",
      "backbone.blocks.7.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,515 - mmcv - INFO - \n",
      "backbone.blocks.7.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,516 - mmcv - INFO - \n",
      "backbone.blocks.7.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,516 - mmcv - INFO - \n",
      "backbone.blocks.7.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,516 - mmcv - INFO - \n",
      "backbone.blocks.7.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,519 - mmcv - INFO - \n",
      "backbone.blocks.7.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,519 - mmcv - INFO - \n",
      "backbone.blocks.7.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,520 - mmcv - INFO - \n",
      "backbone.blocks.7.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,520 - mmcv - INFO - \n",
      "backbone.blocks.7.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,521 - mmcv - INFO - \n",
      "backbone.blocks.7.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,521 - mmcv - INFO - \n",
      "backbone.blocks.7.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,522 - mmcv - INFO - \n",
      "backbone.blocks.7.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,522 - mmcv - INFO - \n",
      "backbone.blocks.7.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,523 - mmcv - INFO - \n",
      "backbone.blocks.8.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,523 - mmcv - INFO - \n",
      "backbone.blocks.8.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,524 - mmcv - INFO - \n",
      "backbone.blocks.8.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,524 - mmcv - INFO - \n",
      "backbone.blocks.8.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,524 - mmcv - INFO - \n",
      "backbone.blocks.8.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,525 - mmcv - INFO - \n",
      "backbone.blocks.8.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,527 - mmcv - INFO - \n",
      "backbone.blocks.8.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,528 - mmcv - INFO - \n",
      "backbone.blocks.8.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,528 - mmcv - INFO - \n",
      "backbone.blocks.8.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,529 - mmcv - INFO - \n",
      "backbone.blocks.8.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,529 - mmcv - INFO - \n",
      "backbone.blocks.8.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,530 - mmcv - INFO - \n",
      "backbone.blocks.8.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,530 - mmcv - INFO - \n",
      "backbone.blocks.8.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,531 - mmcv - INFO - \n",
      "backbone.blocks.8.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,531 - mmcv - INFO - \n",
      "backbone.blocks.8.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,532 - mmcv - INFO - \n",
      "backbone.blocks.8.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,532 - mmcv - INFO - \n",
      "backbone.blocks.8.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,533 - mmcv - INFO - \n",
      "backbone.blocks.8.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,533 - mmcv - INFO - \n",
      "backbone.blocks.8.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,534 - mmcv - INFO - \n",
      "backbone.blocks.9.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,534 - mmcv - INFO - \n",
      "backbone.blocks.9.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,535 - mmcv - INFO - \n",
      "backbone.blocks.9.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,537 - mmcv - INFO - \n",
      "backbone.blocks.9.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,537 - mmcv - INFO - \n",
      "backbone.blocks.9.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,538 - mmcv - INFO - \n",
      "backbone.blocks.9.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,538 - mmcv - INFO - \n",
      "backbone.blocks.9.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,539 - mmcv - INFO - \n",
      "backbone.blocks.9.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,539 - mmcv - INFO - \n",
      "backbone.blocks.9.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,540 - mmcv - INFO - \n",
      "backbone.blocks.9.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,540 - mmcv - INFO - \n",
      "backbone.blocks.9.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,541 - mmcv - INFO - \n",
      "backbone.blocks.9.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,541 - mmcv - INFO - \n",
      "backbone.blocks.9.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,543 - mmcv - INFO - \n",
      "backbone.blocks.9.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,543 - mmcv - INFO - \n",
      "backbone.blocks.9.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,544 - mmcv - INFO - \n",
      "backbone.blocks.9.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,545 - mmcv - INFO - \n",
      "backbone.blocks.9.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,545 - mmcv - INFO - \n",
      "backbone.blocks.9.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,546 - mmcv - INFO - \n",
      "backbone.blocks.9.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,546 - mmcv - INFO - \n",
      "backbone.blocks.10.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,549 - mmcv - INFO - \n",
      "backbone.blocks.10.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,550 - mmcv - INFO - \n",
      "backbone.blocks.10.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,550 - mmcv - INFO - \n",
      "backbone.blocks.10.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,551 - mmcv - INFO - \n",
      "backbone.blocks.10.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,551 - mmcv - INFO - \n",
      "backbone.blocks.10.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,552 - mmcv - INFO - \n",
      "backbone.blocks.10.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,552 - mmcv - INFO - \n",
      "backbone.blocks.10.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,553 - mmcv - INFO - \n",
      "backbone.blocks.10.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,553 - mmcv - INFO - \n",
      "backbone.blocks.10.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,553 - mmcv - INFO - \n",
      "backbone.blocks.10.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,554 - mmcv - INFO - \n",
      "backbone.blocks.10.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,554 - mmcv - INFO - \n",
      "backbone.blocks.10.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,555 - mmcv - INFO - \n",
      "backbone.blocks.10.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,555 - mmcv - INFO - \n",
      "backbone.blocks.10.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,556 - mmcv - INFO - \n",
      "backbone.blocks.10.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,558 - mmcv - INFO - \n",
      "backbone.blocks.10.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,558 - mmcv - INFO - \n",
      "backbone.blocks.10.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,559 - mmcv - INFO - \n",
      "backbone.blocks.10.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,559 - mmcv - INFO - \n",
      "backbone.blocks.11.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,560 - mmcv - INFO - \n",
      "backbone.blocks.11.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,560 - mmcv - INFO - \n",
      "backbone.blocks.11.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,560 - mmcv - INFO - \n",
      "backbone.blocks.11.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,561 - mmcv - INFO - \n",
      "backbone.blocks.11.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,562 - mmcv - INFO - \n",
      "backbone.blocks.11.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,563 - mmcv - INFO - \n",
      "backbone.blocks.11.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,563 - mmcv - INFO - \n",
      "backbone.blocks.11.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,564 - mmcv - INFO - \n",
      "backbone.blocks.11.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,564 - mmcv - INFO - \n",
      "backbone.blocks.11.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,564 - mmcv - INFO - \n",
      "backbone.blocks.11.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,565 - mmcv - INFO - \n",
      "backbone.blocks.11.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,565 - mmcv - INFO - \n",
      "backbone.blocks.11.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,566 - mmcv - INFO - \n",
      "backbone.blocks.11.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,566 - mmcv - INFO - \n",
      "backbone.blocks.11.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,567 - mmcv - INFO - \n",
      "backbone.blocks.11.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,567 - mmcv - INFO - \n",
      "backbone.blocks.11.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,567 - mmcv - INFO - \n",
      "backbone.blocks.11.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,568 - mmcv - INFO - \n",
      "backbone.blocks.11.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,570 - mmcv - INFO - \n",
      "backbone.blocks.12.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,570 - mmcv - INFO - \n",
      "backbone.blocks.12.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,571 - mmcv - INFO - \n",
      "backbone.blocks.12.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,571 - mmcv - INFO - \n",
      "backbone.blocks.12.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,572 - mmcv - INFO - \n",
      "backbone.blocks.12.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,572 - mmcv - INFO - \n",
      "backbone.blocks.12.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,573 - mmcv - INFO - \n",
      "backbone.blocks.12.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,573 - mmcv - INFO - \n",
      "backbone.blocks.12.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,573 - mmcv - INFO - \n",
      "backbone.blocks.12.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,574 - mmcv - INFO - \n",
      "backbone.blocks.12.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,574 - mmcv - INFO - \n",
      "backbone.blocks.12.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,575 - mmcv - INFO - \n",
      "backbone.blocks.12.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,576 - mmcv - INFO - \n",
      "backbone.blocks.12.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,577 - mmcv - INFO - \n",
      "backbone.blocks.12.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,577 - mmcv - INFO - \n",
      "backbone.blocks.12.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,578 - mmcv - INFO - \n",
      "backbone.blocks.12.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,578 - mmcv - INFO - \n",
      "backbone.blocks.12.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,578 - mmcv - INFO - \n",
      "backbone.blocks.12.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,579 - mmcv - INFO - \n",
      "backbone.blocks.12.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,579 - mmcv - INFO - \n",
      "backbone.blocks.13.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,580 - mmcv - INFO - \n",
      "backbone.blocks.13.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,580 - mmcv - INFO - \n",
      "backbone.blocks.13.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,580 - mmcv - INFO - \n",
      "backbone.blocks.13.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,581 - mmcv - INFO - \n",
      "backbone.blocks.13.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,581 - mmcv - INFO - \n",
      "backbone.blocks.13.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,582 - mmcv - INFO - \n",
      "backbone.blocks.13.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,582 - mmcv - INFO - \n",
      "backbone.blocks.13.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,583 - mmcv - INFO - \n",
      "backbone.blocks.13.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,583 - mmcv - INFO - \n",
      "backbone.blocks.13.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,583 - mmcv - INFO - \n",
      "backbone.blocks.13.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,584 - mmcv - INFO - \n",
      "backbone.blocks.13.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,584 - mmcv - INFO - \n",
      "backbone.blocks.13.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,585 - mmcv - INFO - \n",
      "backbone.blocks.13.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,585 - mmcv - INFO - \n",
      "backbone.blocks.13.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,588 - mmcv - INFO - \n",
      "backbone.blocks.13.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,589 - mmcv - INFO - \n",
      "backbone.blocks.13.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,589 - mmcv - INFO - \n",
      "backbone.blocks.13.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,589 - mmcv - INFO - \n",
      "backbone.blocks.13.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,590 - mmcv - INFO - \n",
      "backbone.blocks.14.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,590 - mmcv - INFO - \n",
      "backbone.blocks.14.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,591 - mmcv - INFO - \n",
      "backbone.blocks.14.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,591 - mmcv - INFO - \n",
      "backbone.blocks.14.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,591 - mmcv - INFO - \n",
      "backbone.blocks.14.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,592 - mmcv - INFO - \n",
      "backbone.blocks.14.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,592 - mmcv - INFO - \n",
      "backbone.blocks.14.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,594 - mmcv - INFO - \n",
      "backbone.blocks.14.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,595 - mmcv - INFO - \n",
      "backbone.blocks.14.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,595 - mmcv - INFO - \n",
      "backbone.blocks.14.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,595 - mmcv - INFO - \n",
      "backbone.blocks.14.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,596 - mmcv - INFO - \n",
      "backbone.blocks.14.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,596 - mmcv - INFO - \n",
      "backbone.blocks.14.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,597 - mmcv - INFO - \n",
      "backbone.blocks.14.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,597 - mmcv - INFO - \n",
      "backbone.blocks.14.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,598 - mmcv - INFO - \n",
      "backbone.blocks.14.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,598 - mmcv - INFO - \n",
      "backbone.blocks.14.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,598 - mmcv - INFO - \n",
      "backbone.blocks.14.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,599 - mmcv - INFO - \n",
      "backbone.blocks.14.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,599 - mmcv - INFO - \n",
      "backbone.blocks.15.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,600 - mmcv - INFO - \n",
      "backbone.blocks.15.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,600 - mmcv - INFO - \n",
      "backbone.blocks.15.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,601 - mmcv - INFO - \n",
      "backbone.blocks.15.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,603 - mmcv - INFO - \n",
      "backbone.blocks.15.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,603 - mmcv - INFO - \n",
      "backbone.blocks.15.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,604 - mmcv - INFO - \n",
      "backbone.blocks.15.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,604 - mmcv - INFO - \n",
      "backbone.blocks.15.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,604 - mmcv - INFO - \n",
      "backbone.blocks.15.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,605 - mmcv - INFO - \n",
      "backbone.blocks.15.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,605 - mmcv - INFO - \n",
      "backbone.blocks.15.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,606 - mmcv - INFO - \n",
      "backbone.blocks.15.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,606 - mmcv - INFO - \n",
      "backbone.blocks.15.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,607 - mmcv - INFO - \n",
      "backbone.blocks.15.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,607 - mmcv - INFO - \n",
      "backbone.blocks.15.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,608 - mmcv - INFO - \n",
      "backbone.blocks.15.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,608 - mmcv - INFO - \n",
      "backbone.blocks.15.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,609 - mmcv - INFO - \n",
      "backbone.blocks.15.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,609 - mmcv - INFO - \n",
      "backbone.blocks.15.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,609 - mmcv - INFO - \n",
      "backbone.blocks.16.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,610 - mmcv - INFO - \n",
      "backbone.blocks.16.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,610 - mmcv - INFO - \n",
      "backbone.blocks.16.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,611 - mmcv - INFO - \n",
      "backbone.blocks.16.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,611 - mmcv - INFO - \n",
      "backbone.blocks.16.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,613 - mmcv - INFO - \n",
      "backbone.blocks.16.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,613 - mmcv - INFO - \n",
      "backbone.blocks.16.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,614 - mmcv - INFO - \n",
      "backbone.blocks.16.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,614 - mmcv - INFO - \n",
      "backbone.blocks.16.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,614 - mmcv - INFO - \n",
      "backbone.blocks.16.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,615 - mmcv - INFO - \n",
      "backbone.blocks.16.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,615 - mmcv - INFO - \n",
      "backbone.blocks.16.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,616 - mmcv - INFO - \n",
      "backbone.blocks.16.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,616 - mmcv - INFO - \n",
      "backbone.blocks.16.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,617 - mmcv - INFO - \n",
      "backbone.blocks.16.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,617 - mmcv - INFO - \n",
      "backbone.blocks.16.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,618 - mmcv - INFO - \n",
      "backbone.blocks.16.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,618 - mmcv - INFO - \n",
      "backbone.blocks.16.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,618 - mmcv - INFO - \n",
      "backbone.blocks.16.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,619 - mmcv - INFO - \n",
      "backbone.blocks.17.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,619 - mmcv - INFO - \n",
      "backbone.blocks.17.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,620 - mmcv - INFO - \n",
      "backbone.blocks.17.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,620 - mmcv - INFO - \n",
      "backbone.blocks.17.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,621 - mmcv - INFO - \n",
      "backbone.blocks.17.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,621 - mmcv - INFO - \n",
      "backbone.blocks.17.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,621 - mmcv - INFO - \n",
      "backbone.blocks.17.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,625 - mmcv - INFO - \n",
      "backbone.blocks.17.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,625 - mmcv - INFO - \n",
      "backbone.blocks.17.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,626 - mmcv - INFO - \n",
      "backbone.blocks.17.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,626 - mmcv - INFO - \n",
      "backbone.blocks.17.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,627 - mmcv - INFO - \n",
      "backbone.blocks.17.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,627 - mmcv - INFO - \n",
      "backbone.blocks.17.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,628 - mmcv - INFO - \n",
      "backbone.blocks.17.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,630 - mmcv - INFO - \n",
      "backbone.blocks.17.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,630 - mmcv - INFO - \n",
      "backbone.blocks.17.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,630 - mmcv - INFO - \n",
      "backbone.blocks.17.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,631 - mmcv - INFO - \n",
      "backbone.blocks.17.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,631 - mmcv - INFO - \n",
      "backbone.blocks.17.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,632 - mmcv - INFO - \n",
      "backbone.blocks.18.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,632 - mmcv - INFO - \n",
      "backbone.blocks.18.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,633 - mmcv - INFO - \n",
      "backbone.blocks.18.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,633 - mmcv - INFO - \n",
      "backbone.blocks.18.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,633 - mmcv - INFO - \n",
      "backbone.blocks.18.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,634 - mmcv - INFO - \n",
      "backbone.blocks.18.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,634 - mmcv - INFO - \n",
      "backbone.blocks.18.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,635 - mmcv - INFO - \n",
      "backbone.blocks.18.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,635 - mmcv - INFO - \n",
      "backbone.blocks.18.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,636 - mmcv - INFO - \n",
      "backbone.blocks.18.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,636 - mmcv - INFO - \n",
      "backbone.blocks.18.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,636 - mmcv - INFO - \n",
      "backbone.blocks.18.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,638 - mmcv - INFO - \n",
      "backbone.blocks.18.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,638 - mmcv - INFO - \n",
      "backbone.blocks.18.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,638 - mmcv - INFO - \n",
      "backbone.blocks.18.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,639 - mmcv - INFO - \n",
      "backbone.blocks.18.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,639 - mmcv - INFO - \n",
      "backbone.blocks.18.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,640 - mmcv - INFO - \n",
      "backbone.blocks.18.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,640 - mmcv - INFO - \n",
      "backbone.blocks.18.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,641 - mmcv - INFO - \n",
      "backbone.blocks.19.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,641 - mmcv - INFO - \n",
      "backbone.blocks.19.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,641 - mmcv - INFO - \n",
      "backbone.blocks.19.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,642 - mmcv - INFO - \n",
      "backbone.blocks.19.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,642 - mmcv - INFO - \n",
      "backbone.blocks.19.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,643 - mmcv - INFO - \n",
      "backbone.blocks.19.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,643 - mmcv - INFO - \n",
      "backbone.blocks.19.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,643 - mmcv - INFO - \n",
      "backbone.blocks.19.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,644 - mmcv - INFO - \n",
      "backbone.blocks.19.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,644 - mmcv - INFO - \n",
      "backbone.blocks.19.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,645 - mmcv - INFO - \n",
      "backbone.blocks.19.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,645 - mmcv - INFO - \n",
      "backbone.blocks.19.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,645 - mmcv - INFO - \n",
      "backbone.blocks.19.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,646 - mmcv - INFO - \n",
      "backbone.blocks.19.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,646 - mmcv - INFO - \n",
      "backbone.blocks.19.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,647 - mmcv - INFO - \n",
      "backbone.blocks.19.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,648 - mmcv - INFO - \n",
      "backbone.blocks.19.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,648 - mmcv - INFO - \n",
      "backbone.blocks.19.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,649 - mmcv - INFO - \n",
      "backbone.blocks.19.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,649 - mmcv - INFO - \n",
      "backbone.blocks.20.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,650 - mmcv - INFO - \n",
      "backbone.blocks.20.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,650 - mmcv - INFO - \n",
      "backbone.blocks.20.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,650 - mmcv - INFO - \n",
      "backbone.blocks.20.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,651 - mmcv - INFO - \n",
      "backbone.blocks.20.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,651 - mmcv - INFO - \n",
      "backbone.blocks.20.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,652 - mmcv - INFO - \n",
      "backbone.blocks.20.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,652 - mmcv - INFO - \n",
      "backbone.blocks.20.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,653 - mmcv - INFO - \n",
      "backbone.blocks.20.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,653 - mmcv - INFO - \n",
      "backbone.blocks.20.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,653 - mmcv - INFO - \n",
      "backbone.blocks.20.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,654 - mmcv - INFO - \n",
      "backbone.blocks.20.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,654 - mmcv - INFO - \n",
      "backbone.blocks.20.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,655 - mmcv - INFO - \n",
      "backbone.blocks.20.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,655 - mmcv - INFO - \n",
      "backbone.blocks.20.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,655 - mmcv - INFO - \n",
      "backbone.blocks.20.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,656 - mmcv - INFO - \n",
      "backbone.blocks.20.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,656 - mmcv - INFO - \n",
      "backbone.blocks.20.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,657 - mmcv - INFO - \n",
      "backbone.blocks.20.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,657 - mmcv - INFO - \n",
      "backbone.blocks.21.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,657 - mmcv - INFO - \n",
      "backbone.blocks.21.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,658 - mmcv - INFO - \n",
      "backbone.blocks.21.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,659 - mmcv - INFO - \n",
      "backbone.blocks.21.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,659 - mmcv - INFO - \n",
      "backbone.blocks.21.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,660 - mmcv - INFO - \n",
      "backbone.blocks.21.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,660 - mmcv - INFO - \n",
      "backbone.blocks.21.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,660 - mmcv - INFO - \n",
      "backbone.blocks.21.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,661 - mmcv - INFO - \n",
      "backbone.blocks.21.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,661 - mmcv - INFO - \n",
      "backbone.blocks.21.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,662 - mmcv - INFO - \n",
      "backbone.blocks.21.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,662 - mmcv - INFO - \n",
      "backbone.blocks.21.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,663 - mmcv - INFO - \n",
      "backbone.blocks.21.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,663 - mmcv - INFO - \n",
      "backbone.blocks.21.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,663 - mmcv - INFO - \n",
      "backbone.blocks.21.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,664 - mmcv - INFO - \n",
      "backbone.blocks.21.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,664 - mmcv - INFO - \n",
      "backbone.blocks.21.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,664 - mmcv - INFO - \n",
      "backbone.blocks.21.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,665 - mmcv - INFO - \n",
      "backbone.blocks.21.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,665 - mmcv - INFO - \n",
      "backbone.blocks.22.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,666 - mmcv - INFO - \n",
      "backbone.blocks.22.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,666 - mmcv - INFO - \n",
      "backbone.blocks.22.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,667 - mmcv - INFO - \n",
      "backbone.blocks.22.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,667 - mmcv - INFO - \n",
      "backbone.blocks.22.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,667 - mmcv - INFO - \n",
      "backbone.blocks.22.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,668 - mmcv - INFO - \n",
      "backbone.blocks.22.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,668 - mmcv - INFO - \n",
      "backbone.blocks.22.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,669 - mmcv - INFO - \n",
      "backbone.blocks.22.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,669 - mmcv - INFO - \n",
      "backbone.blocks.22.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,669 - mmcv - INFO - \n",
      "backbone.blocks.22.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,670 - mmcv - INFO - \n",
      "backbone.blocks.22.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,670 - mmcv - INFO - \n",
      "backbone.blocks.22.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,671 - mmcv - INFO - \n",
      "backbone.blocks.22.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,671 - mmcv - INFO - \n",
      "backbone.blocks.22.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,672 - mmcv - INFO - \n",
      "backbone.blocks.22.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,672 - mmcv - INFO - \n",
      "backbone.blocks.22.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,672 - mmcv - INFO - \n",
      "backbone.blocks.22.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,673 - mmcv - INFO - \n",
      "backbone.blocks.22.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,673 - mmcv - INFO - \n",
      "backbone.blocks.23.norm1.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,674 - mmcv - INFO - \n",
      "backbone.blocks.23.norm1.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,674 - mmcv - INFO - \n",
      "backbone.blocks.23.attn.q_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,674 - mmcv - INFO - \n",
      "backbone.blocks.23.attn.v_bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,675 - mmcv - INFO - \n",
      "backbone.blocks.23.attn.q_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,675 - mmcv - INFO - \n",
      "backbone.blocks.23.attn.k_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,676 - mmcv - INFO - \n",
      "backbone.blocks.23.attn.v_proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,676 - mmcv - INFO - \n",
      "backbone.blocks.23.attn.proj.weight - torch.Size([1024, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,677 - mmcv - INFO - \n",
      "backbone.blocks.23.attn.proj.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,677 - mmcv - INFO - \n",
      "backbone.blocks.23.norm2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,677 - mmcv - INFO - \n",
      "backbone.blocks.23.norm2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,678 - mmcv - INFO - \n",
      "backbone.blocks.23.mlp.w1.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,678 - mmcv - INFO - \n",
      "backbone.blocks.23.mlp.w1.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,679 - mmcv - INFO - \n",
      "backbone.blocks.23.mlp.w2.weight - torch.Size([2730, 1024]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,679 - mmcv - INFO - \n",
      "backbone.blocks.23.mlp.w2.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,679 - mmcv - INFO - \n",
      "backbone.blocks.23.mlp.ffn_ln.weight - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,680 - mmcv - INFO - \n",
      "backbone.blocks.23.mlp.ffn_ln.bias - torch.Size([2730]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,680 - mmcv - INFO - \n",
      "backbone.blocks.23.mlp.w3.weight - torch.Size([1024, 2730]): \n",
      "Initialized by user-defined `init_weights` in ViT  \n",
      " \n",
      "2024-10-07 20:01:19,681 - mmcv - INFO - \n",
      "backbone.blocks.23.mlp.w3.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,681 - mmcv - INFO - \n",
      "backbone.out_norm.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,682 - mmcv - INFO - \n",
      "backbone.out_norm.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,682 - mmcv - INFO - \n",
      "neck.p2.1.weight - torch.Size([512, 1024, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-10-07 20:01:19,682 - mmcv - INFO - \n",
      "neck.p2.2.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,684 - mmcv - INFO - \n",
      "neck.p2.2.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,685 - mmcv - INFO - \n",
      "neck.p2.5.weight - torch.Size([256, 512, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-10-07 20:01:19,685 - mmcv - INFO - \n",
      "neck.p2.6.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,686 - mmcv - INFO - \n",
      "neck.p2.6.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,686 - mmcv - INFO - \n",
      "neck.p2.8.weight - torch.Size([256, 256, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-10-07 20:01:19,686 - mmcv - INFO - \n",
      "neck.p2.9.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,687 - mmcv - INFO - \n",
      "neck.p2.9.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,687 - mmcv - INFO - \n",
      "neck.p2.11.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-10-07 20:01:19,688 - mmcv - INFO - \n",
      "neck.p2.12.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,688 - mmcv - INFO - \n",
      "neck.p2.12.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,689 - mmcv - INFO - \n",
      "neck.p3.1.weight - torch.Size([512, 1024, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-10-07 20:01:19,689 - mmcv - INFO - \n",
      "neck.p3.2.weight - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,689 - mmcv - INFO - \n",
      "neck.p3.2.bias - torch.Size([512]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,690 - mmcv - INFO - \n",
      "neck.p3.4.weight - torch.Size([256, 512, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-10-07 20:01:19,690 - mmcv - INFO - \n",
      "neck.p3.5.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,691 - mmcv - INFO - \n",
      "neck.p3.5.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,691 - mmcv - INFO - \n",
      "neck.p3.7.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-10-07 20:01:19,691 - mmcv - INFO - \n",
      "neck.p3.8.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,692 - mmcv - INFO - \n",
      "neck.p3.8.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,692 - mmcv - INFO - \n",
      "neck.p4.0.weight - torch.Size([256, 1024, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-10-07 20:01:19,693 - mmcv - INFO - \n",
      "neck.p4.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,693 - mmcv - INFO - \n",
      "neck.p4.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,693 - mmcv - INFO - \n",
      "neck.p4.3.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-10-07 20:01:19,694 - mmcv - INFO - \n",
      "neck.p4.4.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,694 - mmcv - INFO - \n",
      "neck.p4.4.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,695 - mmcv - INFO - \n",
      "neck.p5.1.weight - torch.Size([256, 1024, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-10-07 20:01:19,695 - mmcv - INFO - \n",
      "neck.p5.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,696 - mmcv - INFO - \n",
      "neck.p5.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,696 - mmcv - INFO - \n",
      "neck.p5.4.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-10-07 20:01:19,697 - mmcv - INFO - \n",
      "neck.p5.5.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,697 - mmcv - INFO - \n",
      "neck.p5.5.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,697 - mmcv - INFO - \n",
      "neck.p6.1.weight - torch.Size([1024, 1024, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-10-07 20:01:19,698 - mmcv - INFO - \n",
      "neck.p6.2.weight - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,698 - mmcv - INFO - \n",
      "neck.p6.2.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,699 - mmcv - INFO - \n",
      "neck.p6.4.weight - torch.Size([256, 1024, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-10-07 20:01:19,699 - mmcv - INFO - \n",
      "neck.p6.5.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,699 - mmcv - INFO - \n",
      "neck.p6.5.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,701 - mmcv - INFO - \n",
      "neck.p6.7.weight - torch.Size([256, 256, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-10-07 20:01:19,701 - mmcv - INFO - \n",
      "neck.p6.8.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,702 - mmcv - INFO - \n",
      "neck.p6.8.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,702 - mmcv - INFO - \n",
      "query_head.transformer.level_embeds - torch.Size([5, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,702 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.weight - torch.Size([320, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,703 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.0.attentions.0.sampling_offsets.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,703 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.0.attentions.0.attention_weights.weight - torch.Size([160, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,704 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.0.attentions.0.attention_weights.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,704 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.0.attentions.0.value_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,705 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.0.attentions.0.value_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,705 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.0.attentions.0.output_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,705 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.0.attentions.0.output_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,706 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,706 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,707 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,707 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,707 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.0.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,708 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.0.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,708 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.0.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,709 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.0.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,709 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.weight - torch.Size([320, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,710 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.1.attentions.0.sampling_offsets.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,710 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.1.attentions.0.attention_weights.weight - torch.Size([160, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,710 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.1.attentions.0.attention_weights.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,711 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.1.attentions.0.value_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,711 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.1.attentions.0.value_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,712 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.1.attentions.0.output_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,712 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.1.attentions.0.output_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,713 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,713 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,713 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,714 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,714 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.1.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,715 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.1.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,715 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.1.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,716 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.1.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,716 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.weight - torch.Size([320, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,716 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.2.attentions.0.sampling_offsets.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,717 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.2.attentions.0.attention_weights.weight - torch.Size([160, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,717 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.2.attentions.0.attention_weights.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,718 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.2.attentions.0.value_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,718 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.2.attentions.0.value_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,718 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.2.attentions.0.output_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,719 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.2.attentions.0.output_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,719 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,720 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,720 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,721 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,721 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.2.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,721 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.2.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,722 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.2.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,722 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.2.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,723 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.weight - torch.Size([320, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,723 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.3.attentions.0.sampling_offsets.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,724 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.3.attentions.0.attention_weights.weight - torch.Size([160, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,724 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.3.attentions.0.attention_weights.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,724 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.3.attentions.0.value_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,725 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.3.attentions.0.value_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,725 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.3.attentions.0.output_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,726 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.3.attentions.0.output_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,726 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,726 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,727 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,727 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,728 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.3.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,728 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.3.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,728 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.3.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,729 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.3.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,729 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.weight - torch.Size([320, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,730 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.4.attentions.0.sampling_offsets.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,730 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.4.attentions.0.attention_weights.weight - torch.Size([160, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,730 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.4.attentions.0.attention_weights.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,731 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.4.attentions.0.value_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,731 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.4.attentions.0.value_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,732 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.4.attentions.0.output_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,732 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.4.attentions.0.output_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,733 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,733 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,733 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,734 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,734 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.4.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,735 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.4.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,735 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.4.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,736 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.4.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,736 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.weight - torch.Size([320, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,736 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.5.attentions.0.sampling_offsets.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,737 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.5.attentions.0.attention_weights.weight - torch.Size([160, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,737 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.5.attentions.0.attention_weights.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,738 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.5.attentions.0.value_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,738 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.5.attentions.0.value_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,739 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.5.attentions.0.output_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,739 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.5.attentions.0.output_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,739 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,740 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,740 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,741 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,741 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.5.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,742 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.5.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,742 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.5.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,742 - mmcv - INFO - \n",
      "query_head.transformer.encoder.layers.5.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,743 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,743 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,745 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,745 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,745 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.weight - torch.Size([320, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,746 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.attentions.1.sampling_offsets.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,746 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.attentions.1.attention_weights.weight - torch.Size([160, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,747 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.attentions.1.attention_weights.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,747 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.attentions.1.value_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,747 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.attentions.1.value_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,748 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.attentions.1.output_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,749 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.attentions.1.output_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,749 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,749 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,750 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,750 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,751 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,751 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,752 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,752 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,752 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,753 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.0.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,753 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,754 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,754 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,754 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,755 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.weight - torch.Size([320, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,756 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.attentions.1.sampling_offsets.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,756 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.attentions.1.attention_weights.weight - torch.Size([160, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,756 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.attentions.1.attention_weights.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,757 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.attentions.1.value_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,757 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.attentions.1.value_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,757 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.attentions.1.output_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,758 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.attentions.1.output_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,758 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,759 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,759 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,760 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,760 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,760 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,761 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,761 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,761 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,762 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.1.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,762 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,763 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,763 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,764 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,764 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.weight - torch.Size([320, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,764 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.attentions.1.sampling_offsets.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,765 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.attentions.1.attention_weights.weight - torch.Size([160, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,765 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.attentions.1.attention_weights.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,766 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.attentions.1.value_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,766 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.attentions.1.value_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,766 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.attentions.1.output_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,767 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.attentions.1.output_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,767 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,767 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,768 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,768 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,769 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,769 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,769 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,770 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,770 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,771 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.2.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,771 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,771 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,772 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,772 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,773 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.weight - torch.Size([320, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,773 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.attentions.1.sampling_offsets.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,774 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.attentions.1.attention_weights.weight - torch.Size([160, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,774 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.attentions.1.attention_weights.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,774 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.attentions.1.value_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,775 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.attentions.1.value_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,775 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.attentions.1.output_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,776 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.attentions.1.output_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,776 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,776 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,777 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,777 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,778 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,778 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,779 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,779 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,780 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,780 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.3.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,781 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,781 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,781 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,782 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,782 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.weight - torch.Size([320, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,783 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.attentions.1.sampling_offsets.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,783 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.attentions.1.attention_weights.weight - torch.Size([160, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,784 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.attentions.1.attention_weights.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,784 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.attentions.1.value_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,784 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.attentions.1.value_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,785 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.attentions.1.output_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,785 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.attentions.1.output_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,786 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,786 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,787 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,787 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,787 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,788 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,788 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,789 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,789 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,790 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.4.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,790 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_weight - torch.Size([768, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,790 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.attentions.0.attn.in_proj_bias - torch.Size([768]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,791 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,791 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.attentions.0.attn.out_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,792 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.weight - torch.Size([320, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,792 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.attentions.1.sampling_offsets.bias - torch.Size([320]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,792 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.attentions.1.attention_weights.weight - torch.Size([160, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,793 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.attentions.1.attention_weights.bias - torch.Size([160]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,793 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.attentions.1.value_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,793 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.attentions.1.value_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,794 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.attentions.1.output_proj.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,794 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.attentions.1.output_proj.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,795 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.ffns.0.layers.0.0.weight - torch.Size([2048, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,795 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.ffns.0.layers.0.0.bias - torch.Size([2048]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,796 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.ffns.0.layers.1.weight - torch.Size([256, 2048]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,796 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.ffns.0.layers.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,796 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.norms.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,797 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.norms.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,797 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.norms.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,798 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.norms.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,798 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.norms.2.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,798 - mmcv - INFO - \n",
      "query_head.transformer.decoder.layers.5.norms.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,799 - mmcv - INFO - \n",
      "query_head.transformer.decoder.ref_point_head.0.weight - torch.Size([256, 512]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,799 - mmcv - INFO - \n",
      "query_head.transformer.decoder.ref_point_head.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,800 - mmcv - INFO - \n",
      "query_head.transformer.decoder.ref_point_head.2.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,800 - mmcv - INFO - \n",
      "query_head.transformer.decoder.ref_point_head.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,800 - mmcv - INFO - \n",
      "query_head.transformer.decoder.norm.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,801 - mmcv - INFO - \n",
      "query_head.transformer.decoder.norm.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,801 - mmcv - INFO - \n",
      "query_head.transformer.enc_output.weight - torch.Size([256, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,802 - mmcv - INFO - \n",
      "query_head.transformer.enc_output.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,802 - mmcv - INFO - \n",
      "query_head.transformer.enc_output_norm.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,802 - mmcv - INFO - \n",
      "query_head.transformer.enc_output_norm.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,803 - mmcv - INFO - \n",
      "query_head.transformer.query_embed.weight - torch.Size([1500, 256]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,803 - mmcv - INFO - \n",
      "query_head.transformer.aux_pos_trans.0.weight - torch.Size([256, 512]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,804 - mmcv - INFO - \n",
      "query_head.transformer.aux_pos_trans.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,804 - mmcv - INFO - \n",
      "query_head.transformer.aux_pos_trans.1.weight - torch.Size([256, 512]): \n",
      "Initialized by user-defined `init_weights` in CoDINOHead  \n",
      " \n",
      "2024-10-07 20:01:19,805 - mmcv - INFO - \n",
      "query_head.transformer.aux_pos_trans.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,805 - mmcv - INFO - \n",
      "query_head.transformer.aux_pos_trans_norm.0.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,805 - mmcv - INFO - \n",
      "query_head.transformer.aux_pos_trans_norm.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,806 - mmcv - INFO - \n",
      "query_head.transformer.aux_pos_trans_norm.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,806 - mmcv - INFO - \n",
      "query_head.transformer.aux_pos_trans_norm.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,807 - mmcv - INFO - \n",
      "query_head.downsample.0.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,807 - mmcv - INFO - \n",
      "query_head.downsample.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,808 - mmcv - INFO - \n",
      "query_head.downsample.1.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,808 - mmcv - INFO - \n",
      "query_head.downsample.1.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,808 - mmcv - INFO - \n",
      "query_head.cls_branches.0.weight - torch.Size([10, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,809 - mmcv - INFO - \n",
      "query_head.cls_branches.0.bias - torch.Size([10]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,809 - mmcv - INFO - \n",
      "query_head.cls_branches.1.weight - torch.Size([10, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,810 - mmcv - INFO - \n",
      "query_head.cls_branches.1.bias - torch.Size([10]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,810 - mmcv - INFO - \n",
      "query_head.cls_branches.2.weight - torch.Size([10, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,811 - mmcv - INFO - \n",
      "query_head.cls_branches.2.bias - torch.Size([10]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,811 - mmcv - INFO - \n",
      "query_head.cls_branches.3.weight - torch.Size([10, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,812 - mmcv - INFO - \n",
      "query_head.cls_branches.3.bias - torch.Size([10]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,812 - mmcv - INFO - \n",
      "query_head.cls_branches.4.weight - torch.Size([10, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,813 - mmcv - INFO - \n",
      "query_head.cls_branches.4.bias - torch.Size([10]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,813 - mmcv - INFO - \n",
      "query_head.cls_branches.5.weight - torch.Size([10, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,813 - mmcv - INFO - \n",
      "query_head.cls_branches.5.bias - torch.Size([10]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,814 - mmcv - INFO - \n",
      "query_head.cls_branches.6.weight - torch.Size([10, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,814 - mmcv - INFO - \n",
      "query_head.cls_branches.6.bias - torch.Size([10]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,815 - mmcv - INFO - \n",
      "query_head.reg_branches.0.0.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,815 - mmcv - INFO - \n",
      "query_head.reg_branches.0.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,816 - mmcv - INFO - \n",
      "query_head.reg_branches.0.2.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,816 - mmcv - INFO - \n",
      "query_head.reg_branches.0.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,816 - mmcv - INFO - \n",
      "query_head.reg_branches.0.4.weight - torch.Size([4, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,817 - mmcv - INFO - \n",
      "query_head.reg_branches.0.4.bias - torch.Size([4]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,817 - mmcv - INFO - \n",
      "query_head.reg_branches.1.0.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,818 - mmcv - INFO - \n",
      "query_head.reg_branches.1.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,818 - mmcv - INFO - \n",
      "query_head.reg_branches.1.2.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,819 - mmcv - INFO - \n",
      "query_head.reg_branches.1.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,819 - mmcv - INFO - \n",
      "query_head.reg_branches.1.4.weight - torch.Size([4, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,820 - mmcv - INFO - \n",
      "query_head.reg_branches.1.4.bias - torch.Size([4]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,820 - mmcv - INFO - \n",
      "query_head.reg_branches.2.0.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,820 - mmcv - INFO - \n",
      "query_head.reg_branches.2.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,821 - mmcv - INFO - \n",
      "query_head.reg_branches.2.2.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,822 - mmcv - INFO - \n",
      "query_head.reg_branches.2.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,822 - mmcv - INFO - \n",
      "query_head.reg_branches.2.4.weight - torch.Size([4, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,822 - mmcv - INFO - \n",
      "query_head.reg_branches.2.4.bias - torch.Size([4]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,823 - mmcv - INFO - \n",
      "query_head.reg_branches.3.0.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,823 - mmcv - INFO - \n",
      "query_head.reg_branches.3.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,824 - mmcv - INFO - \n",
      "query_head.reg_branches.3.2.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,824 - mmcv - INFO - \n",
      "query_head.reg_branches.3.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,825 - mmcv - INFO - \n",
      "query_head.reg_branches.3.4.weight - torch.Size([4, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,825 - mmcv - INFO - \n",
      "query_head.reg_branches.3.4.bias - torch.Size([4]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,825 - mmcv - INFO - \n",
      "query_head.reg_branches.4.0.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,826 - mmcv - INFO - \n",
      "query_head.reg_branches.4.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,826 - mmcv - INFO - \n",
      "query_head.reg_branches.4.2.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,827 - mmcv - INFO - \n",
      "query_head.reg_branches.4.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,827 - mmcv - INFO - \n",
      "query_head.reg_branches.4.4.weight - torch.Size([4, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,827 - mmcv - INFO - \n",
      "query_head.reg_branches.4.4.bias - torch.Size([4]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,828 - mmcv - INFO - \n",
      "query_head.reg_branches.5.0.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,828 - mmcv - INFO - \n",
      "query_head.reg_branches.5.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,829 - mmcv - INFO - \n",
      "query_head.reg_branches.5.2.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,831 - mmcv - INFO - \n",
      "query_head.reg_branches.5.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,831 - mmcv - INFO - \n",
      "query_head.reg_branches.5.4.weight - torch.Size([4, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,849 - mmcv - INFO - \n",
      "query_head.reg_branches.5.4.bias - torch.Size([4]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,850 - mmcv - INFO - \n",
      "query_head.reg_branches.6.0.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,850 - mmcv - INFO - \n",
      "query_head.reg_branches.6.0.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,851 - mmcv - INFO - \n",
      "query_head.reg_branches.6.2.weight - torch.Size([256, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,851 - mmcv - INFO - \n",
      "query_head.reg_branches.6.2.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,851 - mmcv - INFO - \n",
      "query_head.reg_branches.6.4.weight - torch.Size([4, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,852 - mmcv - INFO - \n",
      "query_head.reg_branches.6.4.bias - torch.Size([4]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,852 - mmcv - INFO - \n",
      "query_head.label_embedding.weight - torch.Size([10, 256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,853 - mmcv - INFO - \n",
      "rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,853 - mmcv - INFO - \n",
      "rpn_head.rpn_conv.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,854 - mmcv - INFO - \n",
      "rpn_head.rpn_cls.weight - torch.Size([9, 256, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,854 - mmcv - INFO - \n",
      "rpn_head.rpn_cls.bias - torch.Size([9]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,854 - mmcv - INFO - \n",
      "rpn_head.rpn_reg.weight - torch.Size([36, 256, 1, 1]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,855 - mmcv - INFO - \n",
      "rpn_head.rpn_reg.bias - torch.Size([36]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,855 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.fc_cls.weight - torch.Size([11, 1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,856 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.fc_cls.bias - torch.Size([11]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,856 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.fc_reg.weight - torch.Size([4, 1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,857 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.fc_reg.bias - torch.Size([4]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,857 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.shared_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,857 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.shared_convs.0.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,858 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.shared_convs.0.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,858 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.shared_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,859 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.shared_convs.1.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,859 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.shared_convs.1.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,860 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.shared_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,860 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.shared_convs.2.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,861 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.shared_convs.2.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,861 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.shared_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,862 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.shared_convs.3.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,862 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.shared_convs.3.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,862 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,863 - mmcv - INFO - \n",
      "roi_head.0.bbox_head.shared_fcs.0.bias - torch.Size([1024]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,863 - mmcv - INFO - \n",
      "bbox_head.0.cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,864 - mmcv - INFO - \n",
      "bbox_head.0.cls_convs.0.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,864 - mmcv - INFO - \n",
      "bbox_head.0.cls_convs.0.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,865 - mmcv - INFO - \n",
      "bbox_head.0.reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,865 - mmcv - INFO - \n",
      "bbox_head.0.reg_convs.0.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,866 - mmcv - INFO - \n",
      "bbox_head.0.reg_convs.0.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,866 - mmcv - INFO - \n",
      "bbox_head.0.atss_cls.weight - torch.Size([10, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,866 - mmcv - INFO - \n",
      "bbox_head.0.atss_cls.bias - torch.Size([10]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,867 - mmcv - INFO - \n",
      "bbox_head.0.atss_reg.weight - torch.Size([4, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,867 - mmcv - INFO - \n",
      "bbox_head.0.atss_reg.bias - torch.Size([4]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,868 - mmcv - INFO - \n",
      "bbox_head.0.atss_centerness.weight - torch.Size([1, 256, 3, 3]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,868 - mmcv - INFO - \n",
      "bbox_head.0.atss_centerness.bias - torch.Size([1]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,868 - mmcv - INFO - \n",
      "bbox_head.0.scales.0.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,869 - mmcv - INFO - \n",
      "bbox_head.0.scales.1.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,869 - mmcv - INFO - \n",
      "bbox_head.0.scales.2.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,870 - mmcv - INFO - \n",
      "bbox_head.0.scales.3.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,870 - mmcv - INFO - \n",
      "bbox_head.0.scales.4.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n",
      "2024-10-07 20:01:19,870 - mmcv - INFO - \n",
      "bbox_head.0.scales.5.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoDETR  \n",
      " \n"
     ]
    }
   ],
   "source": [
    "# 모델 build 및 pretrained network 불러오기\n",
    "model = build_detector(cfg.model)\n",
    "model.init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 364990707\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'Total number of parameters: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모든 레이어를 동결 (requires_grad를 False로 설정)\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# # 미세 조정을 위해 학습 가능하게 열 레이어 설정\n",
    "# # backbone의 마지막 블록을 학습 가능하게 설정\n",
    "# # for param in model.backbone.blocks[23].parameters():\n",
    "# #     param.requires_grad = True\n",
    "\n",
    "# # # RPN과 ROI head의 학습 가능하게 설정\n",
    "# for param in model.rpn_head.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# for param in model.roi_head.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# for param in model.bbox_head.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# 학습 가능한 파라미터 확인\n",
    "# trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "# print(f'학습 가능한 파라미터 수: {len(trainable_params)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-07 20:01:22,220 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2024-10-07 20:01:22,395 - mmdet - INFO - Start running, host: root@instance-11503, work_dir: /data/ephemeral/home/taehan/test/level2-objectdetection-cv-18/Co-DETR/work_dirs/co_dino_5scale_vit_large_coco_transfer\n",
      "2024-10-07 20:01:22,397 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(NORMAL      ) NumClassCheckHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2024-10-07 20:01:22,397 - mmdet - INFO - workflow: [('train', 1)], max: 16 epochs\n",
      "2024-10-07 20:01:22,398 - mmdet - INFO - Checkpoints will be saved to /data/ephemeral/home/taehan/test/level2-objectdetection-cv-18/Co-DETR/work_dirs/co_dino_5scale_vit_large_coco_transfer by HardDiskBackend.\n",
      "/data/ephemeral/home/taehan/test/level2-objectdetection-cv-18/Co-DETR/mmdet/models/utils/positional_encoding.py:81: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = self.temperature**(2 * (dim_t // 2) / self.num_feats)\n",
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/data/ephemeral/home/taehan/test/level2-objectdetection-cv-18/Co-DETR/projects/models/transformer.py:476: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = 10000**(2 * (dim_t // 2) / pos_feat)\n",
      "/opt/conda/lib/python3.10/site-packages/mmcv/cnn/bricks/transformer.py:812: UserWarning: Use same attn_mask in all attentions in DetrTransformerDecoderLayer \n",
      "  warnings.warn(f'Use same attn_mask in all attentions in '\n",
      "/data/ephemeral/home/taehan/test/level2-objectdetection-cv-18/Co-DETR/projects/models/co_dino_head.py:353: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  t = torch.range(0, len(gt_labels) - 1).long().cuda()\n",
      "/data/ephemeral/home/taehan/test/level2-objectdetection-cv-18/Co-DETR/projects/models/co_deformable_detr_head.py:1031: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  bbox_index = indexes // self.num_classes\n",
      "/data/ephemeral/home/taehan/test/level2-objectdetection-cv-18/Co-DETR/projects/models/transformer.py:180: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  dim_t = temperature**(2 * (dim_t // 2) / num_pos_feats)\n",
      "2024-10-07 20:03:46,276 - mmdet - INFO - Epoch [1][50/4883]\tlr: 5.351e-07, eta: 2 days, 14:24:13, time: 2.877, data_time: 0.049, memory: 17704, enc_loss_cls: 0.1690, enc_loss_bbox: 2.4154, enc_loss_iou: 1.8803, loss_cls: 0.2291, loss_bbox: 2.4083, loss_iou: 1.8803, d0.loss_cls: 0.1628, d0.loss_bbox: 2.4684, d0.loss_iou: 1.8990, d1.loss_cls: 0.1651, d1.loss_bbox: 2.4333, d1.loss_iou: 1.8927, d2.loss_cls: 0.1787, d2.loss_bbox: 2.4284, d2.loss_iou: 1.8825, d3.loss_cls: 0.2895, d3.loss_bbox: 2.4138, d3.loss_iou: 1.8831, d4.loss_cls: 0.1787, d4.loss_bbox: 2.4095, d4.loss_iou: 1.8819, dn_loss_cls: 1.2828, dn_loss_bbox: 0.7033, dn_loss_iou: 0.6474, d0.dn_loss_cls: 1.5218, d0.dn_loss_bbox: 0.7033, d0.dn_loss_iou: 0.6475, d1.dn_loss_cls: 1.4854, d1.dn_loss_bbox: 0.7033, d1.dn_loss_iou: 0.6475, d2.dn_loss_cls: 1.3577, d2.dn_loss_bbox: 0.7033, d2.dn_loss_iou: 0.6474, d3.dn_loss_cls: 1.3765, d3.dn_loss_bbox: 0.7033, d3.dn_loss_iou: 0.6474, d4.dn_loss_cls: 1.3737, d4.dn_loss_bbox: 0.7033, d4.dn_loss_iou: 0.6474, loss_rpn_cls: 8.2680, loss_rpn_bbox: 0.3241, loss_cls0: 17.6915, acc0: 68.4102, loss_bbox0: 0.0635, loss_cls1: 13.7430, loss_bbox1: 12.2679, loss_centerness1: 7.5922, loss_cls_aux0: 3.5090, loss_bbox_aux0: 0.1276, loss_iou_aux0: 0.0679, d0.loss_cls_aux0: 4.2282, d0.loss_bbox_aux0: 0.1267, d0.loss_iou_aux0: 0.0664, d1.loss_cls_aux0: 4.1495, d1.loss_bbox_aux0: 0.1269, d1.loss_iou_aux0: 0.0665, d2.loss_cls_aux0: 3.6820, d2.loss_bbox_aux0: 0.1270, d2.loss_iou_aux0: 0.0668, d3.loss_cls_aux0: 3.7264, d3.loss_bbox_aux0: 0.1272, d3.loss_iou_aux0: 0.0671, d4.loss_cls_aux0: 3.7292, d4.loss_bbox_aux0: 0.1274, d4.loss_iou_aux0: 0.0675, loss_cls_aux1: 0.5994, loss_bbox_aux1: 1.3708, loss_iou_aux1: 1.0305, d0.loss_cls_aux1: 0.7201, d0.loss_bbox_aux1: 1.3711, d0.loss_iou_aux1: 1.0307, d1.loss_cls_aux1: 0.7055, d1.loss_bbox_aux1: 1.3710, d1.loss_iou_aux1: 1.0307, d2.loss_cls_aux1: 0.6362, d2.loss_bbox_aux1: 1.3710, d2.loss_iou_aux1: 1.0306, d3.loss_cls_aux1: 0.6400, d3.loss_bbox_aux1: 1.3709, d3.loss_iou_aux1: 1.0306, d4.loss_cls_aux1: 0.6420, d4.loss_bbox_aux1: 1.3708, d4.loss_iou_aux1: 1.0305, loss: 150.5443, grad_norm: 485.7635\n",
      "2024-10-07 20:05:59,707 - mmdet - INFO - Epoch [1][100/4883]\tlr: 1.030e-06, eta: 2 days, 12:06:08, time: 2.669, data_time: 0.006, memory: 18886, enc_loss_cls: 0.2930, enc_loss_bbox: 2.1659, enc_loss_iou: 1.6107, loss_cls: 0.7519, loss_bbox: 2.1641, loss_iou: 1.6049, d0.loss_cls: 0.3305, d0.loss_bbox: 2.2143, d0.loss_iou: 1.6423, d1.loss_cls: 0.4254, d1.loss_bbox: 2.2047, d1.loss_iou: 1.6107, d2.loss_cls: 0.6165, d2.loss_bbox: 2.1707, d2.loss_iou: 1.6088, d3.loss_cls: 0.6687, d3.loss_bbox: 2.1592, d3.loss_iou: 1.6155, d4.loss_cls: 0.6215, d4.loss_bbox: 2.1664, d4.loss_iou: 1.6035, dn_loss_cls: 1.0075, dn_loss_bbox: 0.7077, dn_loss_iou: 0.6477, d0.dn_loss_cls: 1.2535, d0.dn_loss_bbox: 0.7078, d0.dn_loss_iou: 0.6481, d1.dn_loss_cls: 1.1204, d1.dn_loss_bbox: 0.7078, d1.dn_loss_iou: 0.6479, d2.dn_loss_cls: 1.0081, d2.dn_loss_bbox: 0.7077, d2.dn_loss_iou: 0.6478, d3.dn_loss_cls: 1.0203, d3.dn_loss_bbox: 0.7077, d3.dn_loss_iou: 0.6478, d4.dn_loss_cls: 1.0510, d4.dn_loss_bbox: 0.7077, d4.dn_loss_iou: 0.6477, loss_rpn_cls: 7.3468, loss_rpn_bbox: 0.3239, loss_cls0: 1.8393, acc0: 97.9297, loss_bbox0: 0.5657, loss_cls1: 13.2644, loss_bbox1: 11.8281, loss_centerness1: 7.4835, loss_cls_aux0: 1.9297, loss_bbox_aux0: 0.7066, loss_iou_aux0: 0.3473, d0.loss_cls_aux0: 2.4599, d0.loss_bbox_aux0: 0.7051, d0.loss_iou_aux0: 0.3445, d1.loss_cls_aux0: 2.1936, d1.loss_bbox_aux0: 0.7054, d1.loss_iou_aux0: 0.3449, d2.loss_cls_aux0: 1.8867, d2.loss_bbox_aux0: 0.7056, d2.loss_iou_aux0: 0.3454, d3.loss_cls_aux0: 1.9079, d3.loss_bbox_aux0: 0.7059, d3.loss_iou_aux0: 0.3459, d4.loss_cls_aux0: 1.9682, d4.loss_bbox_aux0: 0.7062, d4.loss_iou_aux0: 0.3466, loss_cls_aux1: 0.5393, loss_bbox_aux1: 1.3179, loss_iou_aux1: 0.9987, d0.loss_cls_aux1: 0.6665, d0.loss_bbox_aux1: 1.3184, d0.loss_iou_aux1: 0.9995, d1.loss_cls_aux1: 0.6070, d1.loss_bbox_aux1: 1.3184, d1.loss_iou_aux1: 0.9992, d2.loss_cls_aux1: 0.5417, d2.loss_bbox_aux1: 1.3184, d2.loss_iou_aux1: 0.9990, d3.loss_cls_aux1: 0.5427, d3.loss_bbox_aux1: 1.3183, d3.loss_iou_aux1: 0.9989, d4.loss_cls_aux1: 0.5610, d4.loss_bbox_aux1: 1.3181, d4.loss_iou_aux1: 0.9988, loss: 123.5124, grad_norm: 313.6936\n",
      "2024-10-07 20:08:02,228 - mmdet - INFO - Epoch [1][150/4883]\tlr: 1.525e-06, eta: 2 days, 9:44:04, time: 2.450, data_time: 0.006, memory: 18886, enc_loss_cls: 0.3222, enc_loss_bbox: 2.0649, enc_loss_iou: 1.6419, loss_cls: 0.7823, loss_bbox: 2.0426, loss_iou: 1.6479, d0.loss_cls: 0.3886, d0.loss_bbox: 2.1144, d0.loss_iou: 1.6642, d1.loss_cls: 0.5437, d1.loss_bbox: 2.0830, d1.loss_iou: 1.6472, d2.loss_cls: 0.6065, d2.loss_bbox: 2.0538, d2.loss_iou: 1.6525, d3.loss_cls: 0.6684, d3.loss_bbox: 2.0562, d3.loss_iou: 1.6440, d4.loss_cls: 0.6889, d4.loss_bbox: 2.0422, d4.loss_iou: 1.6533, dn_loss_cls: 0.9593, dn_loss_bbox: 0.6621, dn_loss_iou: 0.6461, d0.dn_loss_cls: 1.0215, d0.dn_loss_bbox: 0.6609, d0.dn_loss_iou: 0.6475, d1.dn_loss_cls: 0.9051, d1.dn_loss_bbox: 0.6611, d1.dn_loss_iou: 0.6470, d2.dn_loss_cls: 0.9168, d2.dn_loss_bbox: 0.6614, d2.dn_loss_iou: 0.6467, d3.dn_loss_cls: 0.9329, d3.dn_loss_bbox: 0.6617, d3.dn_loss_iou: 0.6464, d4.dn_loss_cls: 0.9628, d4.dn_loss_bbox: 0.6619, d4.dn_loss_iou: 0.6462, loss_rpn_cls: 5.4050, loss_rpn_bbox: 0.3203, loss_cls0: 1.7719, acc0: 97.3203, loss_bbox0: 0.8854, loss_cls1: 12.4897, loss_bbox1: 11.8424, loss_centerness1: 7.4786, loss_cls_aux0: 1.5323, loss_bbox_aux0: 0.8528, loss_iou_aux0: 0.4522, d0.loss_cls_aux0: 1.5781, d0.loss_bbox_aux0: 0.8480, d0.loss_iou_aux0: 0.4463, d1.loss_cls_aux0: 1.3734, d1.loss_bbox_aux0: 0.8487, d1.loss_iou_aux0: 0.4472, d2.loss_cls_aux0: 1.3264, d2.loss_bbox_aux0: 0.8496, d2.loss_iou_aux0: 0.4482, d3.loss_cls_aux0: 1.3656, d3.loss_bbox_aux0: 0.8506, d3.loss_iou_aux0: 0.4495, d4.loss_cls_aux0: 1.4448, d4.loss_bbox_aux0: 0.8517, d4.loss_iou_aux0: 0.4508, loss_cls_aux1: 0.4812, loss_bbox_aux1: 1.2186, loss_iou_aux1: 0.9991, d0.loss_cls_aux1: 0.4762, d0.loss_bbox_aux1: 1.2192, d0.loss_iou_aux1: 1.0006, d1.loss_cls_aux1: 0.4314, d1.loss_bbox_aux1: 1.2190, d1.loss_iou_aux1: 1.0001, d2.loss_cls_aux1: 0.4205, d2.loss_bbox_aux1: 1.2188, d2.loss_iou_aux1: 0.9997, d3.loss_cls_aux1: 0.4221, d3.loss_bbox_aux1: 1.2187, d3.loss_iou_aux1: 0.9995, d4.loss_cls_aux1: 0.4536, d4.loss_bbox_aux1: 1.2186, d4.loss_iou_aux1: 0.9993, loss: 116.1618, grad_norm: 287.5329\n",
      "2024-10-07 20:10:18,793 - mmdet - INFO - Epoch [1][200/4883]\tlr: 2.020e-06, eta: 2 days, 10:03:14, time: 2.731, data_time: 0.006, memory: 21675, enc_loss_cls: 0.3623, enc_loss_bbox: 1.8846, enc_loss_iou: 1.4045, loss_cls: 0.6327, loss_bbox: 1.8541, loss_iou: 1.3880, d0.loss_cls: 0.4824, d0.loss_bbox: 1.9660, d0.loss_iou: 1.4157, d1.loss_cls: 0.5060, d1.loss_bbox: 1.9298, d1.loss_iou: 1.3946, d2.loss_cls: 0.5176, d2.loss_bbox: 1.9149, d2.loss_iou: 1.3885, d3.loss_cls: 0.5614, d3.loss_bbox: 1.8832, d3.loss_iou: 1.3852, d4.loss_cls: 0.5764, d4.loss_bbox: 1.8666, d4.loss_iou: 1.3857, dn_loss_cls: 0.9884, dn_loss_bbox: 0.6995, dn_loss_iou: 0.6421, d0.dn_loss_cls: 0.9389, d0.dn_loss_bbox: 0.6932, d0.dn_loss_iou: 0.6424, d1.dn_loss_cls: 0.8738, d1.dn_loss_bbox: 0.6939, d1.dn_loss_iou: 0.6418, d2.dn_loss_cls: 0.9044, d2.dn_loss_bbox: 0.6955, d2.dn_loss_iou: 0.6416, d3.dn_loss_cls: 0.9606, d3.dn_loss_bbox: 0.6970, d3.dn_loss_iou: 0.6417, d4.dn_loss_cls: 0.9865, d4.dn_loss_bbox: 0.6984, d4.dn_loss_iou: 0.6419, loss_rpn_cls: 3.5526, loss_rpn_bbox: 0.3385, loss_cls0: 2.0055, acc0: 96.6680, loss_bbox0: 1.0774, loss_cls1: 11.9768, loss_bbox1: 11.8152, loss_centerness1: 7.5005, loss_cls_aux0: 1.2393, loss_bbox_aux0: 0.8406, loss_iou_aux0: 0.4541, d0.loss_cls_aux0: 1.3831, d0.loss_bbox_aux0: 0.8349, d0.loss_iou_aux0: 0.4448, d1.loss_cls_aux0: 1.2573, d1.loss_bbox_aux0: 0.8361, d1.loss_iou_aux0: 0.4469, d2.loss_cls_aux0: 1.1568, d2.loss_bbox_aux0: 0.8372, d2.loss_iou_aux0: 0.4491, d3.loss_cls_aux0: 1.1477, d3.loss_bbox_aux0: 0.8383, d3.loss_iou_aux0: 0.4511, d4.loss_cls_aux0: 1.1870, d4.loss_bbox_aux0: 0.8395, d4.loss_iou_aux0: 0.4525, loss_cls_aux1: 0.3781, loss_bbox_aux1: 1.3012, loss_iou_aux1: 0.9962, d0.loss_cls_aux1: 0.3913, d0.loss_bbox_aux1: 1.3005, d0.loss_iou_aux1: 0.9983, d1.loss_cls_aux1: 0.3737, d1.loss_bbox_aux1: 1.3009, d1.loss_iou_aux1: 0.9972, d2.loss_cls_aux1: 0.3421, d2.loss_bbox_aux1: 1.3011, d2.loss_iou_aux1: 0.9968, d3.loss_cls_aux1: 0.3361, d3.loss_bbox_aux1: 1.3011, d3.loss_iou_aux1: 0.9965, d4.loss_cls_aux1: 0.3530, d4.loss_bbox_aux1: 1.3012, d4.loss_iou_aux1: 0.9963, loss: 109.7066, grad_norm: 296.6768\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 5.31 GiB (GPU 0; 31.74 GiB total capacity; 22.66 GiB already allocated; 4.06 GiB free; 26.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistributed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/ephemeral/home/taehan/test/level2-objectdetection-cv-18/Co-DETR/mmdet/apis/train.py:245\u001b[0m, in \u001b[0;36mtrain_detector\u001b[0;34m(model, dataset, cfg, distributed, validate, timestamp, meta)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mload_from:\n\u001b[1;32m    244\u001b[0m     runner\u001b[38;5;241m.\u001b[39mload_checkpoint(cfg\u001b[38;5;241m.\u001b[39mload_from)\n\u001b[0;32m--> 245\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmcv/runner/epoch_based_runner.py:136\u001b[0m, in \u001b[0;36mEpochBasedRunner.run\u001b[0;34m(self, data_loaders, workflow, max_epochs, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_epochs:\n\u001b[1;32m    135\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 136\u001b[0m             \u001b[43mepoch_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loaders\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# wait for some hooks like loggers to finish\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter_run\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmcv/runner/epoch_based_runner.py:54\u001b[0m, in \u001b[0;36mEpochBasedRunner.train\u001b[0;34m(self, data_loader, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_hook(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbefore_train_iter\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_iter(data_batch, train_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mafter_train_iter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_batch\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmcv/runner/base_runner.py:317\u001b[0m, in \u001b[0;36mBaseRunner.call_hook\u001b[0;34m(self, fn_name)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Call all hooks.\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    fn_name (str): The function name in each hook to be called, such as\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;124;03m        \"before_train_epoch\".\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hooks:\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/mmcv/runner/hooks/optimizer.py:61\u001b[0m, in \u001b[0;36mOptimizerHook.after_train_iter\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetect_anomalous_params:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetect_anomalous_parameters(runner\u001b[38;5;241m.\u001b[39moutputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m], runner)\n\u001b[0;32m---> 61\u001b[0m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrad_clip \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     grad_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_grads(runner\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/function.py:253\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImplementing both \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackward\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvjp\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for a custom \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFunction is not allowed. You should only implement one \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof them.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    252\u001b[0m user_fn \u001b[38;5;241m=\u001b[39m vjp_fn \u001b[38;5;28;01mif\u001b[39;00m vjp_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Function\u001b[38;5;241m.\u001b[39mvjp \u001b[38;5;28;01melse\u001b[39;00m backward_fn\n\u001b[0;32m--> 253\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43muser_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/fairscale/nn/checkpoint/checkpoint_activations.py:349\u001b[0m, in \u001b[0;36mCheckpointFunction.backward\u001b[0;34m(ctx, *args)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outputs_with_grad) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of the outputs have requires_grad=True, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis checkpoint() is not necessary\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 349\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs_with_grad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_with_grad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(inp\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inp, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m inp \u001b[38;5;129;01min\u001b[39;00m inputs)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m+\u001b[39m grads\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 5.31 GiB (GPU 0; 31.74 GiB total capacity; 22.66 GiB already allocated; 4.06 GiB free; 26.46 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "train_detector(model, datasets[0], cfg, distributed=False, validate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "980dec4bdc0f65d3f181e5891661df87e8769cde5e79cd54bc145a7f830b2685"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
